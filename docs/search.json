[
  {
    "objectID": "Personnel/Reddit_Sentiment/Reddit_Scrape.html",
    "href": "Personnel/Reddit_Sentiment/Reddit_Scrape.html",
    "title": "Begin sentiment Analysis",
    "section": "",
    "text": "import praw\nimport regex as re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\nimport os\nimport sklearn\nimport nltk\n\nMatplotlib created a temporary cache directory at /tmp/matplotlib-rtvczs6a because the default path (/home/jovyan/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\nclientid = ''\nclient_secret = ''\nuser_agent = \"\"\nreddit = praw.Reddit(\n    client_id=clientid,\n    client_secret=client_secret,\n    user_agent=user_agent\n)\nprint(reddit.read_only)\n# Output: True\n\nTrue\nimport re\n\ndef find_matched_terms(text, terms):\n    matched = []\n    for term in terms:\n        # Word-boundary search (e.g., matches \"lead\" but not \"leadership\")\n        pattern = rf'\\b{re.escape(term)}\\b'\n        if re.search(pattern, text, flags=re.IGNORECASE):\n            matched.append(term)\n    return matched\ntar_sub = 'datacenter'\nbattery_terms = ['battery', 'batteries', 'lithium', 'li-ion', 'sodium', 'lead', 'acid', 'ups','sodium','ion']\ntime_filter = 'all'\ndata = []\nseen_comments = set()\n\nfor term in battery_terms:\n    for submission in reddit.subreddit(tar_sub).search(term, sort=\"top\", time_filter=time_filter):\n        submission.comments.replace_more(limit=0)\n        for comment in submission.comments.list():\n            if comment.id in seen_comments:\n                continue\n            text = comment.body.lower()\n            matched_terms = find_matched_terms(text, battery_terms)\n            if matched_terms:\n                data.append({\n                    'comment_id': comment.id,\n                    'author': str(comment.author),\n                    'text': text,\n                    'matched_terms': matched_terms,\n                    'submission_id': submission.id,\n                    'submission_title': submission.title\n                })\n                seen_comments.add(comment.id)\n\n# Convert to DataFrame\ndf = pd.DataFrame(data)\ndf.head()\n\n\n\n\n\n\n\n\ncomment_id\nauthor\ntext\nmatched_terms\nsubmission_id\nsubmission_title\n\n\n\n\n0\ng0bu3y5\nghostalker47423\ndo a visual inspection, and if you see any lea...\n[batteries]\ni3jdwl\nInheriting a 30 kVA UPS with 2 strings of 24 b...\n\n\n1\ng0diub1\nRedebo\ndisconnect the battery strings via the associa...\n[battery, batteries, ups]\ni3jdwl\nInheriting a 30 kVA UPS with 2 strings of 24 b...\n\n\n2\ng0dtxqg\nletsbebuns\nthe batteries should be removed based on age. ...\n[batteries, lead, acid, ups]\ni3jdwl\nInheriting a 30 kVA UPS with 2 strings of 24 b...\n\n\n3\ng0ebpdx\nlooktowindward\nyes, they are a safety hazard. you should call...\n[battery]\ni3jdwl\nInheriting a 30 kVA UPS with 2 strings of 24 b...\n\n\n4\ng0euygg\nxpkranger\ni’m going to get rid of them, waiting on a quo...\n[batteries]\ni3jdwl\nInheriting a 30 kVA UPS with 2 strings of 24 b...\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\nexample = df['text'][1]\nprint(example)\n\nex_analyzer = SentimentIntensityAnalyzer()\n\nex_sent = ex_analyzer.polarity_scores(example)\nprint(ex_sent)\n\ndisconnect the battery strings via the associated battery breaker or switch that is either in the ups or electrically in line with the ups.  if you want to be safer after that, remove the intercell jumpers between each battery (caution, batteries are always 'live' and can present voltage and current when both terminals are touched).  once the batteries are disconnected and just sitting on a shelf, you can leave them there practically forever with no risk.\n\nalso, would definitely recommend rip and replace on a 15 year old ups.  if you are located in the western us, my company can assist if you're in need.\n{'neg': 0.011, 'neu': 0.889, 'pos': 0.1, 'compound': 0.8366}\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n\nanalyzer = SentimentIntensityAnalyzer()\n# Apply VADER to each comment's text\ndf['sentiment'] = df['text'].apply(lambda x: analyzer.polarity_scores(x))\ndf = pd.concat([df.drop('sentiment', axis=1), df['sentiment'].apply(pd.Series)], axis=1)\ndef get_label(score):\n    if score &gt;= 0.05:\n        return 'positive'\n    elif score &lt;= -0.05:\n        return 'negative'\n    else:\n        return 'neutral'\n\ndf['sentiment_label'] = df['compound'].apply(get_label)\ndf.head(3)\n\n\n\n\n\n\n\n\ncomment_id\nauthor\ntext\nmatched_terms\nsubmission_id\nsubmission_title\nneg\nneu\npos\ncompound\nsentiment_label\n\n\n\n\n0\ng0bu3y5\nghostalker47423\ndo a visual inspection, and if you see any lea...\n[batteries]\ni3jdwl\nInheriting a 30 kVA UPS with 2 strings of 24 b...\n0.084\n0.873\n0.043\n-0.4215\nnegative\n\n\n1\ng0diub1\nRedebo\ndisconnect the battery strings via the associa...\n[battery, batteries, ups]\ni3jdwl\nInheriting a 30 kVA UPS with 2 strings of 24 b...\n0.011\n0.889\n0.100\n0.8366\npositive\n\n\n2\ng0dtxqg\nletsbebuns\nthe batteries should be removed based on age. ...\n[batteries, lead, acid, ups]\ni3jdwl\nInheriting a 30 kVA UPS with 2 strings of 24 b...\n0.029\n0.971\n0.000\n-0.2617\nnegative\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Simulate a sample of the df for visualization\ndf_viz = pd.DataFrame({\n    'matched_terms': df['matched_terms'],\n    'sentiment_label': df['sentiment_label']\n})\ndf_exploded = df_viz.explode('matched_terms')\n\n\n# Explode matched_terms to allow grouping by single term\ndf_exploded = df_viz.explode('matched_terms')\n\n# Count sentiment labels per battery type\nsentiment_counts = df_exploded.groupby(['matched_terms', 'sentiment_label']).size().unstack(fill_value=0)\n\n# Plot the sentiment distribution per battery type\nsentiment_counts.plot(kind='bar', stacked=True, figsize=(10, 6))\nplt.title('Sentiment Distribution by Battery Type')\nplt.xlabel('Battery Type')\nplt.ylabel('Number of Comments')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.grid(axis='y')\n\nplt.show()\ndf\n\n\n\n\n\n\n\n\ncomment_id\nauthor\ntext\nmatched_terms\nsubmission_id\nsubmission_title\nneg\nneu\npos\ncompound\nsentiment_label\n\n\n\n\n0\ng0bu3y5\nghostalker47423\ndo a visual inspection, and if you see any lea...\n[batteries]\ni3jdwl\nInheriting a 30 kVA UPS with 2 strings of 24 b...\n0.084\n0.873\n0.043\n-0.4215\nnegative\n\n\n1\ng0diub1\nRedebo\ndisconnect the battery strings via the associa...\n[battery, batteries, ups]\ni3jdwl\nInheriting a 30 kVA UPS with 2 strings of 24 b...\n0.011\n0.889\n0.100\n0.8366\npositive\n\n\n2\ng0dtxqg\nletsbebuns\nthe batteries should be removed based on age. ...\n[batteries, lead, acid, ups]\ni3jdwl\nInheriting a 30 kVA UPS with 2 strings of 24 b...\n0.029\n0.971\n0.000\n-0.2617\nnegative\n\n\n3\ng0ebpdx\nlooktowindward\nyes, they are a safety hazard. you should call...\n[battery]\ni3jdwl\nInheriting a 30 kVA UPS with 2 strings of 24 b...\n0.000\n0.718\n0.282\n0.6705\npositive\n\n\n4\ng0euygg\nxpkranger\ni’m going to get rid of them, waiting on a quo...\n[batteries]\ni3jdwl\nInheriting a 30 kVA UPS with 2 strings of 24 b...\n0.000\n0.807\n0.193\n0.7351\npositive\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n263\nfrhl2ew\nswedishhat\nto be fair, full 19in eia racks with ups's are...\n[ups]\nfemyhi\nDoes anyone here use OCP hardware in their dat...\n0.000\n0.944\n0.056\n0.7391\npositive\n\n\n264\nkih1o5a\nNone\n&gt; finally adding your future generator? ah ha ...\n[lead]\n199drs1\nHow can a Field Controls Engineer get PLC Prog...\n0.056\n0.892\n0.052\n-0.1779\nnegative\n\n\n265\ng9583fq\nRedebo\nyou might ask your provider if they have some ...\n[battery]\njcvdpk\nFloor protection in data center\n0.000\n0.940\n0.060\n0.2732\npositive\n\n\n266\nmmhd66m\nAlligatorDan\nthe engineering mindset on youtube is a great ...\n[ups]\n1jw4mql\nAmazon DCEO\n0.013\n0.827\n0.160\n0.9764\npositive\n\n\n267\nmmgzvfn\nLucky_Luciano73\namazon has hired ex-navy guys that we work wit...\n[ups]\n1jw4mql\nAmazon DCEO\n0.092\n0.718\n0.190\n0.6486\npositive\n\n\n\n\n268 rows × 11 columns"
  },
  {
    "objectID": "Personnel/Reddit_Sentiment/Reddit_Scrape.html#model-is-being-trained-on-the-twitter-data",
    "href": "Personnel/Reddit_Sentiment/Reddit_Scrape.html#model-is-being-trained-on-the-twitter-data",
    "title": "Begin sentiment Analysis",
    "section": "model is being trained on the twitter data",
    "text": "model is being trained on the twitter data\n\nMODEL = f'cardiffnlp/twitter-roberta-base-sentiment'\ntokenizer = AutoTokenizer.from_pretrained(MODEL)\nmodel = AutoModelForSequenceClassification.from_pretrained(MODEL)\n\n\nencoded_text = tokenizer(example,return_tensors='pt')\noutput = model(**encoded_text)\nscores = output[0][0].detach().numpy()\nscores = softmax(scores)\n\n\nscores_dict = {\n    'roberta_neg': scores[0],\n    'roberta_neutral': scores[1],\n    'roberta_post': scores[2]\n}\n\n\nprint(scores_dict)\nprint(ex_sent)\n\n{'roberta_neg': 0.07787177, 'roberta_neutral': 0.6052092, 'roberta_post': 0.31691906}\n{'neg': 0.011, 'neu': 0.889, 'pos': 0.1, 'compound': 0.8366}\n\n\n\nfrom scipy.special import softmax\n\ndef polarity_scores_roberta(text):\n    encoded_text = tokenizer(\n        text,\n        return_tensors='pt',\n        truncation=True,       # THIS is what prevents the crash\n        max_length=512,\n        padding=True\n    )\n    output = model(**encoded_text)\n    scores = output[0][0].detach().numpy()\n    scores = softmax(scores)\n    labels = ['negative', 'neutral', 'positive']\n    return labels[scores.argmax()], scores.max()\n\n\ndf[['roberta_label', 'roberta_score']] = df['text'].apply(\n    lambda x: pd.Series(polarity_scores_roberta(x))\n)\n\n\ndf.head(1)\n\n\n\n\n\n\n\n\ncomment_id\nauthor\ntext\nmatched_terms\nsubmission_id\nsubmission_title\nneg\nneu\npos\ncompound\nsentiment_label\nroberta_label\nroberta_score\n\n\n\n\n0\ng0bu3y5\nghostalker47423\ndo a visual inspection, and if you see any lea...\n[batteries]\ni3jdwl\nInheriting a 30 kVA UPS with 2 strings of 24 b...\n0.084\n0.873\n0.043\n-0.4215\nnegative\nnegative\n0.458596\n\n\n\n\n\n\n\n\ndf_exploded = df.explode('matched_terms')\n\n\n# Group by label to visualize distribution\nlabel_counts = df['roberta_label'].value_counts()\n\n# Plot sentiment label distribution\nplt.figure(figsize=(6, 4))\nlabel_counts.plot(kind='bar', color='skyblue')\nplt.title(\"RoBERTa Sentiment Label Distribution\")\nplt.xlabel(\"Sentiment\")\nplt.ylabel(\"Count\")\nplt.xticks(rotation=0)\nplt.grid(axis='y')\nplt.tight_layout()\nplt.show()\n\n# Plot average sentiment score by battery type\navg_score_by_term = df_exploded.groupby('matched_terms')['roberta_score'].mean().sort_values()\n\nplt.figure(figsize=(8, 5))\navg_score_by_term.plot(kind='barh', color='salmon')\nplt.title(\"Average RoBERTa Sentiment Score by Battery Term\")\nplt.xlabel(\"Average Score\")\nplt.ylabel(\"Battery Term\")\nplt.grid(axis='x')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# ---------------------------\n# Visualization by Sentiment Class and Term\n# ---------------------------\nsentiment_counts = df_exploded.groupby(['matched_terms', 'roberta_label']).size().unstack(fill_value=0)\n\nplt.figure(figsize=(10, 6))\nsentiment_counts.plot(kind='bar', stacked=True, colormap='coolwarm', figsize=(10, 6))\nplt.title(\"Sentiment Distribution per Battery Term\")\nplt.xlabel(\"Battery Term\")\nplt.ylabel(\"Number of Comments\")\nplt.xticks(rotation=45)\nplt.grid(axis='y')\nplt.tight_layout()\nplt.show()\n\n# ---------------------------\n# Drill-down: Most Positive & Negative per Term\n# ---------------------------\nmost_pos_comments = df_exploded.sort_values(by='roberta_score', ascending=False).groupby('matched_terms').first().reset_index()\nmost_neg_comments = df_exploded.sort_values(by='roberta_score').groupby('matched_terms').first().reset_index()\n\n# Combine for review\ndrill_df = pd.merge(\n    most_pos_comments[['matched_terms', 'text', 'roberta_score']],\n    most_neg_comments[['matched_terms', 'text', 'roberta_score']],\n    on='matched_terms',\n    suffixes=('_most_positive', '_most_negative')\n)\ndisplay(drill_df)\n\n&lt;Figure size 1000x600 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmatched_terms\ntext_most_positive\nroberta_score_most_positive\ntext_most_negative\nroberta_score_most_negative\n\n\n\n\n0\nacid\nactually, many ups', especially dc grade ups',...\n0.859889\n\"no such thing as a data center that's too col...\n0.455056\n\n\n1\nbatteries\nthat'll prove to be a disaster if the batterie...\n0.945713\nthis may have been the consensus 5 years ago.\\...\n0.436103\n\n\n2\nbattery\nare all of the raid batteries the same age? an...\n0.913489\ni handle all field ups units for a large truck...\n0.446345\n\n\n3\nion\nyes, it is detailed in their site that the mv ...\n0.865184\n\"no such thing as a data center that's too col...\n0.455056\n\n\n4\nlead\nfirst of all, taking on those data center move...\n0.944411\nit really depends op, working at a dc is great...\n0.407846\n\n\n5\nli-ion\nyes, it is detailed in their site that the mv ...\n0.865184\nof course it's feasible. tesla made mega batte...\n0.643169\n\n\n6\nlithium\nactually, many ups', especially dc grade ups',...\n0.859889\nthis may have been the consensus 5 years ago.\\...\n0.436103\n\n\n7\nups\nthe engineering mindset on youtube is a great ...\n0.973194\nyeah i wish we got more remote hands tickets a...\n0.426720\n\n\n\n\n\n\n\n\nneg_comments = df_exploded[df_exploded['roberta_label'] == 'negative']\nneg_lithium = neg_comments[neg_comments['matched_terms'] == 'lithium']\n\n\n\nfrom nltk.tokenize import RegexpTokenizer\n\ntokenizer = RegexpTokenizer(r'\\w+')  # keeps only words, removes punctuation\n\ndef extract_keywords_no_punkt(text_series):\n    all_words = []\n    for text in text_series:\n        tokens = tokenizer.tokenize(text.lower())\n        filtered = [word for word in tokens if word not in stop_words]\n        all_words.extend(filtered)\n    return Counter(all_words).most_common(20)\n\n\n# Define stop_words using NLTK's built-in list\nfrom nltk.corpus import stopwords\n\n\nnltk.download('stopwords')\nstop_words = set(stopwords.words('english'))\n\n# Now that stop_words is defined, rerun the visualization block\nfrom nltk.tokenize import RegexpTokenizer\nfrom collections import Counter\n\ntokenizer = RegexpTokenizer(r'\\w+')\n\ndef extract_keywords_no_punkt(text_series):\n    all_words = []\n    for text in text_series:\n        tokens = tokenizer.tokenize(text.lower())\n        filtered = [word for word in tokens if word not in stop_words]\n        all_words.extend(filtered)\n    return Counter(all_words).most_common(20)\n\nchemistry_pain_points = {}\n\nbattery_terms = neg_comments['matched_terms'].unique()\n\nfor term in battery_terms:\n    chem_comments = neg_comments[neg_comments['matched_terms'] == term]\n    keywords = extract_keywords_no_punkt(chem_comments['text'])\n    chemistry_pain_points[term] = keywords\n\npain_point_data = []\n\nfor term, keywords in chemistry_pain_points.items():\n    for word, freq in keywords:\n        pain_point_data.append({'battery_chemistry': term, 'keyword': word, 'frequency': freq})\n\npain_point_df = pd.DataFrame(pain_point_data)\n\n# Visualize\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ntop_pain_points = (\n    pain_point_df\n    .sort_values(by='frequency', ascending=False)\n    .groupby('battery_chemistry')\n    .head(5)\n)\n\nplt.figure(figsize=(12, 6))\nsns.barplot(\n    data=top_pain_points,\n    y='keyword',\n    x='frequency',\n    hue='battery_chemistry',\n    dodge=False\n)\nplt.title('Top Pain Point Keywords by Battery Chemistry')\nplt.xlabel('Frequency')\nplt.ylabel('Keyword')\nplt.legend(title='Battery Chemistry', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.grid(axis='x')\nplt.show()\n\n[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Homework",
    "section": "",
    "text": "test\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Examples\n\n\n \n\n\n\n\n\nMay 4, 2025\nLowell Capobianco\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n \n\n\n\n\n\nApr 18, 2025\nLowell Capobianco\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/hw1/hw1_questions.html",
    "href": "projects/hw1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe experiment was one of the largest of its kind. Notably, it was conducted for a politically motivated nonprofit using paper mail solicitations in 2005. These characteristics are important to consider, as donor behavior may have shifted in recent years. For example, individuals might become more politically active—and therefore more willing to donate—during contentious elections, while economic uncertainty could make donors more hesitant to give. Regardless of these contextual differences, we will explore how the researchers designed and analyzed their experiment, and use modern statistical techniques to replicate their findings."
  },
  {
    "objectID": "projects/hw1/hw1_questions.html#introduction",
    "href": "projects/hw1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe experiment was one of the largest of its kind. Notably, it was conducted for a politically motivated nonprofit using paper mail solicitations in 2005. These characteristics are important to consider, as donor behavior may have shifted in recent years. For example, individuals might become more politically active—and therefore more willing to donate—during contentious elections, while economic uncertainty could make donors more hesitant to give. Regardless of these contextual differences, we will explore how the researchers designed and analyzed their experiment, and use modern statistical techniques to replicate their findings."
  },
  {
    "objectID": "projects/hw1/hw1_questions.html#data",
    "href": "projects/hw1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\nFirst we’ll load the data from a dta file and conduct EDA inorder to better understand the datatypes and distrubtion of data.\nWe’ll rename the columns we want to make a distribution plot of and check the distribution and check for any outliers.\n\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n\n\n3 rows × 51 columns\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another. Looking at table 1 in the paper we see the reserachers have provided summary statistics of several features in the data. This allows us to see that the control and treatment group are split evenly among those features. Showing the split allows us to perform useful statics techniques.\nTo verify the success of random assignment, I compare pre-treatment characteristics between the treatment and control groups. Table 1 in the original study shows that the groups are similar across key variables, supporting the claim that any later differences are due to the treatment, not underlying differences.\nI replicate this by testing variables like mrm2 (months since last donation), dormant (donated earlier in 2005), and female. Both t-tests and linear regressions confirm no statistically significant differences, reinforcing that the groups are balanced and that the experimental design is valid.\n\n\n\n\n\n\nVariables To Test at the 95% CI\n\n\n\nmrm2, dormant,female\n\n\n\nWe’ll conduct a t-test with a 95% confidence interval to ensure and verify the months since last donation variable with a linear regression\n\nCreate a list of the variables we want to check\nCreate a function that we can use repedetly\nWe’ll use css styling throughout our analysis for better readability\n\n\n\nvariables_to_test = ['mrm2', 'dormant', 'female']\n\ndef t_test(data, target):\n    control_data = data[data['treatment'] == 0]\n    treatment_data = data[data['treatment'] == 1]\n\n    control_mean = control_data[target].mean()\n    treatment_mean = treatment_data[target].mean()\n\n    control_std = control_data[target].std()\n    treatment_std = treatment_data[target].std()\n\n    control_n = len(control_data[target].dropna())\n    treatment_n = len(treatment_data[target].dropna())\n\n    se = ((control_std**2 / control_n) + (treatment_std**2 / treatment_n)) ** 0.5\n    t_stat = (treatment_mean - control_mean) / se\n\n    p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df=control_n + treatment_n - 2))\n\n    significance = \"significant\" if p_value &lt; 0.05 else \"not significant\"\n    \n\n    res = pd.DataFrame([{\n        't_stat': round(t_stat, 2),\n        'control_mean': round(control_mean, 2),\n        'treatment_mean': round(treatment_mean, 2),\n        'mean_diff': round(treatment_mean - control_mean, 2),\n        'standard_error': round(se, 2),\n        'control_n': control_n,\n        'treatment_n': treatment_n,\n        'p_value':p_value,\n        'significance':significance\n    }])\n    return display(res)\nt_test_results = {}\n\n\nfrom IPython.display import display, HTML\n\nfor var in variables_to_test:\n    res = t_test(data, var)  # This displays a table already\n    html = f\"\"\"\n    &lt;div class ='balance-card'&gt;\n        &lt;h4&gt; {var} — Balance Test&lt;/h4&gt;\n        &lt;p&gt;This section shows a comparison between the treatment and control groups for &lt;code&gt;{var}&lt;/code&gt;. A t-test is used to determine whether the difference is statistically significant at the 95% confidence level.&lt;/p&gt;\n    &lt;/div&gt;\n    \"\"\"\n    display(HTML(html))\n\n\n\n\n\n\n\n\nt_stat\ncontrol_mean\ntreatment_mean\nmean_diff\nstandard_error\ncontrol_n\ntreatment_n\np_value\nsignificance\n\n\n\n\n0\n0.12\n13.0\n13.01\n0.01\n0.11\n16687\n33395\n0.904855\nnot significant\n\n\n\n\n\n\n\n\n    \n         mrm2 — Balance Test\n        This section shows a comparison between the treatment and control groups for mrm2. A t-test is used to determine whether the difference is statistically significant at the 95% confidence level.\n    \n    \n\n\n\n\n\n\n\n\n\nt_stat\ncontrol_mean\ntreatment_mean\nmean_diff\nstandard_error\ncontrol_n\ntreatment_n\np_value\nsignificance\n\n\n\n\n0\n0.17\n0.52\n0.52\n0.0\n0.0\n16687\n33396\n0.861961\nnot significant\n\n\n\n\n\n\n\n\n    \n         dormant — Balance Test\n        This section shows a comparison between the treatment and control groups for dormant. A t-test is used to determine whether the difference is statistically significant at the 95% confidence level.\n    \n    \n\n\n\n\n\n\n\n\n\nt_stat\ncontrol_mean\ntreatment_mean\nmean_diff\nstandard_error\ncontrol_n\ntreatment_n\np_value\nsignificance\n\n\n\n\n0\n-1.75\n0.28\n0.28\n-0.01\n0.0\n16339\n32633\n0.07952\nnot significant\n\n\n\n\n\n\n\n\n    \n         female — Balance Test\n        This section shows a comparison between the treatment and control groups for female. A t-test is used to determine whether the difference is statistically significant at the 95% confidence level.\n    \n    \n\n\n\n\nLinear Regression Results\nUsing a Linear regression we can verfy our results of the t-test for the mrm2 variable\n\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  LinearRegression?Documentation for LinearRegressioniFittedLinearRegression() \n\n\n\n\n\n\n\n\n\n\n\nCoefficient\nEstimate\n\n\n\n\n0\nIntercept\n12.9981\n\n\n1\nTreatment Coefficient\n0.0137"
  },
  {
    "objectID": "projects/hw1/hw1_questions.html#experimental-results",
    "href": "projects/hw1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nI analyzed whether matched donations led to an increased response rate of making a donation.\nTo evaluate whether matching donations increase the likelihood that someone donates, I begin by comparing the share of donors between the treatment and control groups. A barplot shows a higher proportion of donations among individuals who received a match offer. This visual evidence suggests that the match has an encouraging effect on giving behavior.\nTo statistically test this difference, I run both a t-test and a simple linear regression using the binary outcome variable gave. Both methods show a small but statistically significant increase in donation likelihood for the treatment group—confirming the results reported in Table 2A, Panel A of the original paper. This indicates that simply announcing a matching offer increases the probability that someone donates, even if the amount of the match (e.g., 1:1 or 3:1) does not change that decision.\nI also fit a probit regression, which models the probability of donating. While the coefficient is significant and consistent in sign with the linear model, the results do not numerically replicate Table 3 from the paper—likely due to rounding differences, omitted covariates, or reporting inconsistencies noted by the authors themselves. Nonetheless, the directional effect is clear: offering a match increases participation in giving.\nThese results reinforce a key behavioral insight: people are more likely to act charitably when they feel their gift is amplified, even if the actual match size doesn’t substantially change the outcome.\n\n\n\n\n\n\nPercentage of Donators by Treatment Group\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDid Not Give\nGave\n\n\n\n\nControl\n0.982142\n0.017858\n\n\nTreatment\n0.977961\n0.022039\n\n\n\n\n\n\n\nText(0.5, 1.0, 'Percentage of Treatment and Control Populations that Donated')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nT-Test of was a donation made\n\n\n\n\n\n\n\nt_test(data, 'gave')\n\n\n\n\n\n\n\n\nt_stat\ncontrol_mean\ntreatment_mean\nmean_diff\nstandard_error\ncontrol_n\ntreatment_n\np_value\nsignificance\n\n\n\n\n0\n3.21\n0.02\n0.02\n0.0\n0.0\n16687\n33396\n0.001331\nsignificant\n\n\n\n\n\n\n\n\n\n\n\n\n\nProbit Regression\n\n\n\n\n\n\n\nX = data[['treatment']]\ny = data['gave']\n\n# Fit Probit model\nprobit_model = sm.discrete.discrete_model.Probit(y, X).fit()\n\n\ndata['predicted_prob'] = probit_model.predict(X)\n# Extract key regression info\nprobit_df = pd.DataFrame({\n    \"Variable\": probit_model.params.index,\n    \"Coefficient\": probit_model.params.round(4).values,\n    \"Std. Error\": probit_model.bse.round(4).values,\n    \"z-Statistic\": probit_model.tvalues.round(2).values,\n    \"p-Value\": probit_model.pvalues.round(5).values\n})\n\nOptimization terminated successfully.\n         Current function value: 0.301543\n         Iterations 7\n\n\n\n\n\n\n  Probit Regression: Likelihood of Donating\n  \n\n\n\nVariable\nCoefficient\nStd. Error\nz-Statistic\np-Value\n\n\n\n\ntreatment\n-2.0134\n0.0153\n-131.73\n0.0\n\n\n\n\n  Interpretation: The treatment variable has a statistically significant effect on the probability of donating.\n\n\n\n\n\n\n\n\n\n\n\n\nDifferences between Match Rates\nNext, I assess whether the size of the matching grant—specifically 1:1, 2:1, or 3:1—affects the likelihood that individuals make a donation. I restrict the analysis to individuals in the treatment group and conduct a series of t-tests comparing response rates across the different match ratios.\nThe results show no statistically significant differences in donation rates between the 1:1, 2:1, and 3:1 match offers. The mean differences in response rates are small, and p-values well above 0.05 confirm that these differences are not meaningful. This aligns with the authors’ observation on page 8 of the paper that “figures suggest that neither the match threshold nor the example amount had a meaningful influence on behavior.”\nIn short, the data suggest that it’s the presence of a match—not its magnitude—that motivates people to give. This finding has practical implications for fundraising: offering a basic match may be just as effective as offering a more generous one, potentially saving costs for the nonprofit without sacrificing donor engagement.\n\n\n\n\n\n\nMatch Rate Analysis\n\n\n\n\n\n\n\n# Filter to treatment group only\nmatched = data[data['treatment'] == 1]\n\n# Separate by match ratio\ngroup_1_1 = matched[matched['ratio'] == 1]['gave']\ngroup_2_1 = matched[matched['ratio'] == 2]['gave']\ngroup_3_1 = matched[matched['ratio'] == 3]['gave']\n\n# Perform t-tests\nresults = []\n\ndef run_ratio_ttest(group_a, group_b, label_a, label_b):\n    t_stat, p_val = ttest_ind(group_a, group_b, equal_var=False)\n    return {\n        'Group A': label_a,\n        'Group B': label_b,\n        'Mean A': round(group_a.mean(), 4),\n        'Mean B': round(group_b.mean(), 4),\n        'Mean Diff': round(group_b.mean() - group_a.mean(), 4),\n        't_stat': round(t_stat, 3),\n        'p_value': round(p_val, 4),\n        'significance': 'significant' if p_val &lt; 0.05 else 'not significant'\n    }\n\nresults.append(run_ratio_ttest(group_1_1, group_2_1, '1:1', '2:1'))\nresults.append(run_ratio_ttest(group_1_1, group_3_1, '1:1', '3:1'))\nresults.append(run_ratio_ttest(group_2_1, group_3_1, '2:1', '3:1'))\n\n# View as DataFrame\nresults_df = pd.DataFrame(results)\ndisplay(results_df)\n\n\n\n\n\n\n\n\nGroup A\nGroup B\nMean A\nMean B\nMean Diff\nt_stat\np_value\nsignificance\n\n\n\n\n0\n1:1\n2:1\n0.0207\n0.0226\n0.0019\n-0.965\n0.3345\nnot significant\n\n\n1\n1:1\n3:1\n0.0207\n0.0227\n0.0020\n-1.015\n0.3101\nnot significant\n\n\n2\n2:1\n3:1\n0.0226\n0.0227\n0.0001\n-0.050\n0.9600\nnot significant\n\n\n\n\n\n\n\nTo complement the t-tests, I also run a regression to assess the effect of match size on donation behavior. I restrict the sample to the treatment group and regress the binary outcome gave on indicator variables for the match ratios: 2:1 and 3:1, with 1:1 serving as the reference group. This specification allows us to estimate how each match ratio affects the likelihood of giving relative to the 1:1 baseline.\nThe regression coefficients for both 2:1 and 3:1 match ratios are small and not statistically significant. This mirrors the t-test findings and supports the paper’s conclusion that larger match ratios do not meaningfully increase participation. The statistical precision of the estimates is low, with wide confidence intervals crossing zero, reinforcing that any observed differences could plausibly be due to chance. These findings suggest that while match offers increase overall response rates, increasing the match beyond 1:1 yields no additional benefit.\n\n\n\n\n\n\nRatio Analysis\n\n\n\n\n\n\n\nmatched = data[data['treatment'] == 1].copy()\n\nmatched['ratio1'] = (matched['ratio'] == 1).astype(int)\nmatched['ratio2'] = (matched['ratio'] == 2).astype(int)\nmatched['ratio3'] = (matched['ratio'] == 3).astype(int)\nimport statsmodels.api as sm\n\nX = matched[['ratio2', 'ratio3']]  # ratio1 is the omitted (reference) group\nX = sm.add_constant(X)\ny = matched['gave']\n\nmodel = sm.OLS(y, X).fit()\n\nimport pandas as pd\nfrom IPython.display import HTML\n\n# Extract and clean key regression results\ntable = pd.DataFrame({\n    \"Variable\": model.params.index,\n    \"Coefficient\": model.params.round(4).values,\n    \"Std. Error\": model.bse.round(4).values,\n    \"t-Statistic\": model.tvalues.round(2).values,\n    \"p-Value\": model.pvalues.round(5).values\n})\n\ntable['Variable'] = table['Variable'].replace({'const': 'Intercept'})\n\n\n\n\n\n  OLS Regression: Effect of Match Ratios on Giving\n  \n\n\n\nVariable\nCoefficient\nStd. Error\nt-Statistic\np-Value\n\n\n\n\nIntercept\n0.0207\n0.0014\n14.91\n0.00000\n\n\nratio2\n0.0019\n0.0020\n0.96\n0.33828\n\n\nratio3\n0.0020\n0.0020\n1.01\n0.31332\n\n\n\n\n  Note: Reference group is ratio = 1:1.\n\n\n\nTo further examine the effectiveness of different match sizes, I calculate the difference in response rates directly from the data. The increase in giving from a 1:1 to a 2:1 match is approximately 0.19 percentage points, and from 2:1 to 3:1 is just 0.01 percentage points—both very small changes. I then compare these results to the fitted coefficients from the earlier regression, which also show similarly small and statistically insignificant differences between the match levels.\nTaken together, these results suggest that raising the match ratio does not meaningfully affect the likelihood of donating. Whether donors are offered a 1:1, 2:1, or 3:1 match, their behavior appears largely unchanged. This reinforces the paper’s central finding: the presence of a match matters, but its size does not.\n\n\n\n\n\n\nMatch Rate Regression Analysis\n\n\n\n\n\n\n\n# Filter for treatment group\nmatched = data[data['treatment'] == 1]\n\n# Calculate average donation rates\nmean_1_1 = matched[matched['ratio'] == 1]['gave'].mean()\nmean_2_1 = matched[matched['ratio'] == 2]['gave'].mean()\nmean_3_1 = matched[matched['ratio'] == 3]['gave'].mean()\n\n# Differences in means\ndiff_2_1_vs_1_1 = mean_2_1 - mean_1_1\ndiff_3_1_vs_2_1 = mean_3_1 - mean_2_1\n\n# OLS Regression: ratio as categorical\nmodel = smf.ols('gave ~ C(ratio)', data=matched).fit()\n\n# Extract coefficients\ncoef_2_1 = model.params['C(ratio)[T.2]']\ncoef_3_1 = model.params['C(ratio)[T.3]']\n\n# Difference between model coefficients\ndiff_model_2_1_vs_1_1 = coef_2_1\ndiff_model_3_1_vs_2_1 = coef_3_1 - coef_2_1\n\n\n\n\n\n  Differences in Response Rates by Match Ratio\n  \n    Raw Mean Difference (2:1 vs 1:1): 0.0019\n    Raw Mean Difference (3:1 vs 2:1): 0.0001\n    Model Coefficient (2:1 vs 1:1): -1229429281.1791\n    Model Coefficient (3:1 vs 2:1): -0.0001\n  \n  Note: These results suggest no statistically meaningful differences in response rate between 1:1, 2:1, and 3:1 match ratios.\n\n\n\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\nTo test whether the match offer affects how much donors give, I run a t-test and a simple linear regression comparing donation amounts between the treatment and control groups. This analysis includes all individuals, whether or not they donated. The results show a small increase in average donation amount in the treatment group, but the difference is only marginally statistically significant. This suggests that while match offers may slightly increase total donations on average, the effect is likely driven by more people giving—not by individuals giving more. This finding aligns with the broader conclusion that matching incentives affect participation rather than generosity.\n\n\n\n\n\n\nDonation Size Analysis\n\n\n\n\n\n\n\nfrom scipy.stats import ttest_ind\n\n# Separate groups\ncontrol = data[data['treatment'] == 0]['amount']\ntreatment = data[data['treatment'] == 1]['amount']\n\n# T-test\nt_stat, p_value = ttest_ind(treatment, control, equal_var=False)\n\nprint(f\"t = {t_stat:.3f}, p = {p_value:.4f}\")\n\nt = 1.918, p = 0.0551\n\n\nTo isolate the effect of the treatment on the size of the donation among those who actually gave, I limit the sample to donors only and rerun the regression. This allows us to assess whether the match offer influenced how much people gave, conditional on deciding to donate. The coefficient on the treatment variable is small and statistically insignificant, indicating that among donors, those who received a match offer gave approximately the same amount as those who did not. These results suggest that the match influences whether someone donates, but not how much they give once they decide to contribute. Because the treatment was randomly assigned, the coefficient does have a causal interpretation—but here, the causal effect on donation size appears to be negligible.\n\n\n\n\n\n\nRatio Analysis\n\n\n\n\n\n\n\ndonors = data[data['amount'] &gt; 0]\nimport statsmodels.api as sm\n\nX = sm.add_constant(donors['treatment'])  # 1 if matched, 0 if not\ny = donors['amount']\n\nmodel = sm.OLS(y, X).fit()\n# Extract and clean results\nols_df = pd.DataFrame({\n    \"Variable\": model.params.index,\n    \"Coefficient\": model.params.round(4).values,\n    \"Std. Error\": model.bse.round(4).values,\n    \"t-Statistic\": model.tvalues.round(2).values,\n    \"p-Value\": model.pvalues.round(5).values\n})\n\nols_df[\"Variable\"] = ols_df[\"Variable\"].replace({'const': 'Intercept'})\nhtml_table = ols_df.to_html(index=False, classes='table table-sm table-striped', border=0)\n\nThe below graph illustrates visually that were was not a staistically signifcant delta between the contorl and treatment group in our sample.\n\n\n\n\n\n\nPlot Analysis\n\n\n\n\n\n\n\n# Filter to people who donated\ndonors = data[data['amount'] &gt; 0]\ncontrol_donors = donors[donors['treatment'] == 0]\ntreatment_donors = donors[donors['treatment'] == 1]\n\n# Calculate means\ncontrol_mean = control_donors['amount'].mean()\ntreatment_mean = treatment_donors['amount'].mean()"
  },
  {
    "objectID": "projects/hw1/hw1_questions.html#simulation-experiment",
    "href": "projects/hw1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\n\n\n\n\n\nSimulation Using Bernoullui Distrubtion\n\n\n\n\n\n\nFrom out bernoulii parameters we can caclulate the mean and the stndard deviation of the distrubtion\n\np_no =.018\nmu_no_char = p_no\nstd_no_char = (mu_no_char* (1-mu_no_char))**.5\n\np = .022\nmu_char = p\nstd_char =  (mu_char * (1-mu_char))**.5\n\n\n\nThe mean and standard deviation for the respondents who did not receive a donation match is (0.018, 0.13)\nThe mean and standard deviation for the respondents who did receive a donation match is (0.022, 0.15)\n\n\n\nLaw of Large Numbers\nThe Law of Large numbers say the more information we have the better our estimates will be. In statics terminology as we increase our sample size the sample mean will move closer to the population mean. To see this law in action we’ll increase our sample size to 10,00 and calcuate the average as we increase the sample size. This should allign with the means that we know from our benoulli distrbution.\n\nn = 10_000\nnp.random.seed(38)\nno_match_draws = np.random.binomial(1, p_no, size=n)\nmatch_draws = np.random.binomial(1, p, size=n)\ndifferences = match_draws - no_match_draws\ncumulative_avg = np.cumsum(differences) / np.arange(1, 10001)\n\n\n\n\n\n\n\n\n\n\n\n\nCentral Limit Theorem\n\n\n\n\n\n\nCentral Limit Theorem Demo\n\n\n\n\n\n\nThe central limit theorem states that as we increase the sample size of a sample the distrubtion of the samples will become more like the bell-shaped cureve, regardless of the starting distrubtion. To Test this this we’ll create 4 sample sizes from our given bernoulli distribtuion. We should expect to see the central limit theorem ‘kick-in’ and the distribtuion start to become more bellshaped.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n#disibutin parameters\np_no = 0.018\np_match = 0.022\n\n#sample sizes \nsample_sizes = [50, 200, 500, 1000]\n#number of simluatoin of a sample size\nn_sim = 1000\n\nfig, axs = plt.subplots(2, 2, figsize=(12, 8))\naxs = axs.flatten()\n\n\n#loop through the different sample size\nfor i, n in enumerate(sample_sizes):\n    diffs = []\n    for _ in range(n_sim):\n        #pull a no_match from a binomial distrubtion of size 1000\n        no_match = np.random.binomial(1, p_no, size=n)\n        #pull a match from a binomial distrubtion of size 1000\n        match = np.random.binomial(1, p_match, size=n)\n        #append the differences to a running list per sample size\n        diff = match.mean() - no_match.mean()\n        diffs.append(diff)\n\n    # plot the graphs\n    axs[i].hist(diffs, bins=30, color='skyblue', edgecolor='black')\n    axs[i].axvline(p_match - p_no, color='red', linestyle='--', label='True Difference')\n    axs[i].set_title(f\"Sample Size = {n}\")\n    axs[i].set_xlabel(\"Mean Difference (Match - No Match)\")\n    axs[i].set_ylabel(\"Frequency\")\n    axs[i].legend()\n\nplt.suptitle(\"Histograms of Sample Mean Differences — Central Limit Theorem in Action\")\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/hw2/hw2_questions.html",
    "href": "projects/hw2/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\ntodo: Read in data.\ntodo: Compare histograms and means of number of patents by customer status. What do you observe?\n\n\n\n\n\n\nEDA\n\n\n\n\n\n\n\nblueprint_hist = pd.pivot_table(blueprinty, index='iscustomer', values='patents', aggfunc='mean').head()\ndisplay(blueprint_hist)\n\nblueprint_hist = blueprint_hist.reset_index()\n\n\n\n\n\n\n\n\npatents\n\n\niscustomer\n\n\n\n\n\n0\n3.473013\n\n\n1\n4.133056\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn average if a someone is a customer they have slightly more patents then a noncustomer\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\nblueprinty['age_bins']= pd.cut(blueprinty['age'], bins=[0, 20, 30, 40, 50], right=False)\nblueprint_hist_age =pd.crosstab(index=blueprinty['age_bins'], columns=blueprinty['iscustomer'],margins=True,margins_name='Total')\ndisplay(blueprint_hist_age)\n\n\n\n\n\n\n\niscustomer\n0\n1\nTotal\n\n\nage_bins\n\n\n\n\n\n\n\n[0, 20)\n205\n98\n303\n\n\n[20, 30)\n496\n213\n709\n\n\n[30, 40)\n291\n142\n433\n\n\n[40, 50)\n27\n28\n55\n\n\nTotal\n1019\n481\n1500\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nblueprint_hist_region= pd.crosstab(index=blueprinty['region'], columns=blueprinty['iscustomer'],margins=True,margins_name='Total')\ndisplay(blueprint_hist_region)\n\n\n\n\n\n\n\niscustomer\n0\n1\nTotal\n\n\nregion\n\n\n\n\n\n\n\nMidwest\n187\n37\n224\n\n\nNortheast\n273\n328\n601\n\n\nNorthwest\n158\n29\n187\n\n\nSouth\n156\n35\n191\n\n\nSouthwest\n245\n52\n297\n\n\nTotal\n1019\n481\n1500\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntodo: Compare regions and ages by customer status. What do you observe?\nMost Customers are in the 20-30 age group aand are from the Norht East region\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\ntodo: Write down mathematically the likelihood for \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\n\n\n\n\n\n\nLog Likehood for Poission\n\n\n\n\n\n\n\n\n\n\n\nThe probability of observing a count \\(( y_i )\\) for observation \\(( i )\\), given Poisson rate  \\(( \\lambda_i )\\), is:\n\\[\nP(Y_i = y_i \\mid \\lambda_i) = \\frac{e^{-\\lambda_i} \\lambda_i^{y_i}}{y_i!}\n\\]\n\n\n\nAssuming we observe \\(( n )\\) independent data points \\(( y_1, y_2, \\ldots, y_n )\\), each with rate \\(( \\lambda_i )\\), the joint likelihood is the product of the individual probabilities: \\[\n\\mathcal{L}(\\lambda_1, \\ldots, \\lambda_n) = \\prod_{i=1}^{n} \\frac{e^{-\\lambda_i} \\lambda_i^{y_i}}{y_i!}\n\\]\n\n\n\nTaking the natural logarithm of the likelihood simplifies the product into a sum: \\[\n\\log \\mathcal{L} = \\sum_{i=1}^{n} \\left( -\\lambda_i + y_i \\log(\\lambda_i) - \\log(y_i!) \\right)\n\\] This is the log-likelihood function for the Poisson model.\n\n\n\n\n\n\nLog likelihood in code\n\n\n\n\n\n\ntodo: Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:\n\nimport numpy as np\nfrom math import factorial\n\ndef poisson_distro(lmbda, y):\n    return (np.exp(-lmbda) * (lmbda ** y)) / factorial(y)\n\ndef poisson_likelihood(lmbda, y_array):\n    return np.prod([poisson_distro(lmbda, y_i) for y_i in y_array])\n\nfrom scipy.special import gammaln\n\ndef poisson_log_likelihood(lmbda, y_array):\n    y_array = np.array(y_array)\n    return np.sum(-lmbda + y_array * np.log(lmbda) - gammaln(y_array + 1))\n\n\n# Evaluate log-likelihoods across lambda values\nlambda_vals = np.arange(1, 20)\nlog_likelihoods = [poisson_log_likelihood(lmbda, blueprinty['patents'].values) for lmbda in lambda_vals]\n\n\n\n\n\n\n\n\n\n\npoisson_loglikelihood &lt;- function(lambda, Y){\n   ...\n}\ntodo: Use your function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y).\ntodo: If you’re feeling mathematical, take the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. You will find lambda_mle is Ybar, which “feels right” because the mean of a Poisson distribution is lambda.\ntodo: Find the MLE by optimizing your likelihood function with optim() in R or sp.optimize() in Python.__\n\n\n\n\nThe log-likelihood for the entire sample is:\n\\[\n\\log \\mathcal{L}(\\lambda) = \\sum_{i=1}^{n} \\left( -\\lambda + y_i \\log(\\lambda) - \\log(y_i!) \\right)\n\\]\nSimplify:\n\\[\n\\ell(\\lambda) = -n\\lambda + \\left( \\sum_{i=1}^n y_i \\right) \\log(\\lambda) - \\sum_{i=1}^n \\log(y_i!)\n\\]\n\n\n\n\nTo find the MLE, take the derivative and set it equal to zero:\n\\[\n\\frac{d}{d\\lambda} \\ell(\\lambda) = -n + \\frac{\\sum y_i}{\\lambda}\n\\]\nSet the derivative to zero:\n\\[\n-n + \\frac{\\sum y_i}{\\lambda} = 0\n\\]\n\n\n\n\n\\[\n\\frac{\\sum y_i}{\\lambda} = n\n\\quad \\Rightarrow \\quad\n\\lambda = \\frac{1}{n} \\sum y_i\n= \\bar{y}\n\\]\nSo the MLE for ( ) in a Poisson distribution is the sample mean:\n\\[\n\\hat{\\lambda}_{\\text{MLE}} = \\bar{y}\n\\]\n\n#from scipy.optimize import minimize_scalar\nfrom scipy.optimize import minimize_scalar\nfrom scipy.special import gammaln\n# ecause scipy.optimize minimizes by default, we minimize the negative log-likelihood\n\n#Trick the minimze function into findind the maximum log likelhood with a negative\n   #lambda lmbda --&gt; Keep calling the function with lambda as the lmbda value\nobjective = lambda lmbda: -poisson_log_likelihood(lmbda, blueprinty['patents'].values)\n\n# Perform the optimization using bounded scalar minimization\nresult = minimize_scalar(objective, bounds=(0.01, 20), method='bounded')\n\n# Output the MLE estimate for lambda\nlambda_mle = result.x\nlog_likelihood_at_mle = -result.fun\n\n\n\n\n\n   MLE for λ: 3.6847\n   sample mean : 3.6847\n   Log-Likelihood at MLE: -3367.68\n\n\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\nWe assume the Poisson rate parameter ( _i ) varies by observation based on covariates ( X_i ) and a parameter vector ( ):\n\\[\n\\lambda_i = \\exp(X_i^\\top \\beta)\n\\]\nThis ensures ( _i &gt; 0 ) for all ( i ), as required for Poisson distributions. The exponential function is the canonical inverse link function for Poisson regression.\n\n\n\n\nGiven the model ( Y_i (_i) ), the log-likelihood function across all observations is:\n\\[\n\\ell(\\beta) = \\sum_{i=1}^n \\left[ -\\exp(X_i^\\top \\beta) + y_i (X_i^\\top \\beta) - \\log(y_i!) \\right]\n\\]\nThis is the function we will maximize to estimate ( ) using maximum likelihood estimation.\ntodo: Update your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g_inv() to be exp() so that \\(\\lambda_i = e^{X_i'\\beta}\\). For example:\npoisson_regression_likelihood &lt;- function(beta, Y, X){\n   ...\n}\n\ndef poisson_log_likelihood_regression(beta, X, y):\n    # Ensure all inputs are NumPy arrays\n    if not isinstance(beta, np.ndarray):\n        beta = np.asarray(beta)\n    if not isinstance(X, np.ndarray):\n        X = np.asarray(X)\n    if not isinstance(y, np.ndarray):\n        y = np.asarray(y)\n\n    eta = X @ beta\n    lambda_ = np.exp(eta)\n\n    return np.sum(-lambda_ + y * eta - gammaln(y + 1))\n\ntodo: Use your function along with R’s optim() or Python’s sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1’s to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\n\nfrom scipy.optimize import minimize\nblueprinty['age_squared'] = blueprinty['age'] ** 2\nblueprinty['age_scaled'] = (blueprinty['age'] - blueprinty['age'].mean()) / blueprinty['age'].std()\nblueprinty['age_squared'] = blueprinty['age_scaled'] ** 2\n\n\n\nblueprinty['intercept'] = 1\nencoded_region = pd.get_dummies(blueprinty['region'], prefix='region', drop_first=True)\nblueprinty = pd.concat([blueprinty, encoded_region], axis=1)\nX = blueprinty[['intercept', 'age_scaled', 'age_squared', 'region_Northeast', 'region_Northwest',\n       'region_South', 'region_Southwest', 'iscustomer']].astype(float).to_numpy()\n\ny = blueprinty['patents'].values\ninitial_beta = np.zeros(X.shape[1])\nresult = minimize(\n    fun=lambda b: -poisson_log_likelihood_regression(b, X, y),\n    x0=initial_beta,\n    method='BFGS'\n)\nbeta_mle = result.x\nlog_lik_at_mle = -result.fun\n\n\n\n\n\n\nVariable\nEstimate (MLE)\n\n\n\n\nintercept\n1.3447\n\n\nage_scaled\n-0.0577\n\n\nage_squared\n-0.1558\n\n\nregion_Northeast\n0.0292\n\n\nregion_Northwest\n-0.0176\n\n\nregion_South\n0.0566\n\n\nregion_Southwest\n0.0506\n\n\niscustomer\n0.2076\n\n\n\n\n\n\n\n   Log-Likelihood at MLE: -3258.07\n\n\n\ntodo: Check your results using R’s glm() function or Python sm.GLM() function.\n\nimport statsmodels.api as sm\n# Use the same standardized/scaled features\nX_sm = blueprinty[['age_scaled', 'age_squared', 'region_Northeast',\n                   'region_Northwest', 'region_South', 'region_Southwest', 'iscustomer']].astype(float).to_numpy()\n\n# Add intercept (statsmodels handles it with sm.add_constant)\nX_sm = sm.add_constant(X_sm)\n\ny_sm = blueprinty['patents']\nmodel = sm.GLM(y_sm, X_sm, family=sm.families.Poisson())\nresult = model.fit()\n\nprint(result.summary())\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                patents   No. Observations:                 1500\nModel:                            GLM   Df Residuals:                     1492\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3258.1\nDate:                Sun, 04 May 2025   Deviance:                       2143.3\nTime:                        16:03:20   Pearson chi2:                 2.07e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.1360\nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          1.3447      0.038     35.059      0.000       1.270       1.420\nx1            -0.0577      0.015     -3.843      0.000      -0.087      -0.028\nx2            -0.1558      0.014    -11.513      0.000      -0.182      -0.129\nx3             0.0292      0.044      0.669      0.504      -0.056       0.115\nx4            -0.0176      0.054     -0.327      0.744      -0.123       0.088\nx5             0.0566      0.053      1.074      0.283      -0.047       0.160\nx6             0.0506      0.047      1.072      0.284      -0.042       0.143\nx7             0.2076      0.031      6.719      0.000       0.147       0.268\n==============================================================================\n\n\ntodo: Interpret the results.\nThe strongest effect is from iscustomer → customers are more innovative Age has a mild downward effect — and gets stronger with age² Region effects are minor — none stand out as very strong\ntodo: What do you conclude about the effect of Blueprinty’s software on patent success? Because the beta coefficients are not directly interpretable, it may help to create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, use X_0 and your fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences."
  },
  {
    "objectID": "projects/hw2/hw2_questions.html#blueprinty-case-study",
    "href": "projects/hw2/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\ntodo: Read in data.\ntodo: Compare histograms and means of number of patents by customer status. What do you observe?\n\n\n\n\n\n\nEDA\n\n\n\n\n\n\n\nblueprint_hist = pd.pivot_table(blueprinty, index='iscustomer', values='patents', aggfunc='mean').head()\ndisplay(blueprint_hist)\n\nblueprint_hist = blueprint_hist.reset_index()\n\n\n\n\n\n\n\n\npatents\n\n\niscustomer\n\n\n\n\n\n0\n3.473013\n\n\n1\n4.133056\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn average if a someone is a customer they have slightly more patents then a noncustomer\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\nblueprinty['age_bins']= pd.cut(blueprinty['age'], bins=[0, 20, 30, 40, 50], right=False)\nblueprint_hist_age =pd.crosstab(index=blueprinty['age_bins'], columns=blueprinty['iscustomer'],margins=True,margins_name='Total')\ndisplay(blueprint_hist_age)\n\n\n\n\n\n\n\niscustomer\n0\n1\nTotal\n\n\nage_bins\n\n\n\n\n\n\n\n[0, 20)\n205\n98\n303\n\n\n[20, 30)\n496\n213\n709\n\n\n[30, 40)\n291\n142\n433\n\n\n[40, 50)\n27\n28\n55\n\n\nTotal\n1019\n481\n1500\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nblueprint_hist_region= pd.crosstab(index=blueprinty['region'], columns=blueprinty['iscustomer'],margins=True,margins_name='Total')\ndisplay(blueprint_hist_region)\n\n\n\n\n\n\n\niscustomer\n0\n1\nTotal\n\n\nregion\n\n\n\n\n\n\n\nMidwest\n187\n37\n224\n\n\nNortheast\n273\n328\n601\n\n\nNorthwest\n158\n29\n187\n\n\nSouth\n156\n35\n191\n\n\nSouthwest\n245\n52\n297\n\n\nTotal\n1019\n481\n1500\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntodo: Compare regions and ages by customer status. What do you observe?\nMost Customers are in the 20-30 age group aand are from the Norht East region\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\ntodo: Write down mathematically the likelihood for \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\n\n\n\n\n\n\nLog Likehood for Poission\n\n\n\n\n\n\n\n\n\n\n\nThe probability of observing a count \\(( y_i )\\) for observation \\(( i )\\), given Poisson rate  \\(( \\lambda_i )\\), is:\n\\[\nP(Y_i = y_i \\mid \\lambda_i) = \\frac{e^{-\\lambda_i} \\lambda_i^{y_i}}{y_i!}\n\\]\n\n\n\nAssuming we observe \\(( n )\\) independent data points \\(( y_1, y_2, \\ldots, y_n )\\), each with rate \\(( \\lambda_i )\\), the joint likelihood is the product of the individual probabilities: \\[\n\\mathcal{L}(\\lambda_1, \\ldots, \\lambda_n) = \\prod_{i=1}^{n} \\frac{e^{-\\lambda_i} \\lambda_i^{y_i}}{y_i!}\n\\]\n\n\n\nTaking the natural logarithm of the likelihood simplifies the product into a sum: \\[\n\\log \\mathcal{L} = \\sum_{i=1}^{n} \\left( -\\lambda_i + y_i \\log(\\lambda_i) - \\log(y_i!) \\right)\n\\] This is the log-likelihood function for the Poisson model.\n\n\n\n\n\n\nLog likelihood in code\n\n\n\n\n\n\ntodo: Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:\n\nimport numpy as np\nfrom math import factorial\n\ndef poisson_distro(lmbda, y):\n    return (np.exp(-lmbda) * (lmbda ** y)) / factorial(y)\n\ndef poisson_likelihood(lmbda, y_array):\n    return np.prod([poisson_distro(lmbda, y_i) for y_i in y_array])\n\nfrom scipy.special import gammaln\n\ndef poisson_log_likelihood(lmbda, y_array):\n    y_array = np.array(y_array)\n    return np.sum(-lmbda + y_array * np.log(lmbda) - gammaln(y_array + 1))\n\n\n# Evaluate log-likelihoods across lambda values\nlambda_vals = np.arange(1, 20)\nlog_likelihoods = [poisson_log_likelihood(lmbda, blueprinty['patents'].values) for lmbda in lambda_vals]\n\n\n\n\n\n\n\n\n\n\npoisson_loglikelihood &lt;- function(lambda, Y){\n   ...\n}\ntodo: Use your function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y).\ntodo: If you’re feeling mathematical, take the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. You will find lambda_mle is Ybar, which “feels right” because the mean of a Poisson distribution is lambda.\ntodo: Find the MLE by optimizing your likelihood function with optim() in R or sp.optimize() in Python.__\n\n\n\n\nThe log-likelihood for the entire sample is:\n\\[\n\\log \\mathcal{L}(\\lambda) = \\sum_{i=1}^{n} \\left( -\\lambda + y_i \\log(\\lambda) - \\log(y_i!) \\right)\n\\]\nSimplify:\n\\[\n\\ell(\\lambda) = -n\\lambda + \\left( \\sum_{i=1}^n y_i \\right) \\log(\\lambda) - \\sum_{i=1}^n \\log(y_i!)\n\\]\n\n\n\n\nTo find the MLE, take the derivative and set it equal to zero:\n\\[\n\\frac{d}{d\\lambda} \\ell(\\lambda) = -n + \\frac{\\sum y_i}{\\lambda}\n\\]\nSet the derivative to zero:\n\\[\n-n + \\frac{\\sum y_i}{\\lambda} = 0\n\\]\n\n\n\n\n\\[\n\\frac{\\sum y_i}{\\lambda} = n\n\\quad \\Rightarrow \\quad\n\\lambda = \\frac{1}{n} \\sum y_i\n= \\bar{y}\n\\]\nSo the MLE for ( ) in a Poisson distribution is the sample mean:\n\\[\n\\hat{\\lambda}_{\\text{MLE}} = \\bar{y}\n\\]\n\n#from scipy.optimize import minimize_scalar\nfrom scipy.optimize import minimize_scalar\nfrom scipy.special import gammaln\n# ecause scipy.optimize minimizes by default, we minimize the negative log-likelihood\n\n#Trick the minimze function into findind the maximum log likelhood with a negative\n   #lambda lmbda --&gt; Keep calling the function with lambda as the lmbda value\nobjective = lambda lmbda: -poisson_log_likelihood(lmbda, blueprinty['patents'].values)\n\n# Perform the optimization using bounded scalar minimization\nresult = minimize_scalar(objective, bounds=(0.01, 20), method='bounded')\n\n# Output the MLE estimate for lambda\nlambda_mle = result.x\nlog_likelihood_at_mle = -result.fun\n\n\n\n\n\n   MLE for λ: 3.6847\n   sample mean : 3.6847\n   Log-Likelihood at MLE: -3367.68\n\n\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\nWe assume the Poisson rate parameter ( _i ) varies by observation based on covariates ( X_i ) and a parameter vector ( ):\n\\[\n\\lambda_i = \\exp(X_i^\\top \\beta)\n\\]\nThis ensures ( _i &gt; 0 ) for all ( i ), as required for Poisson distributions. The exponential function is the canonical inverse link function for Poisson regression.\n\n\n\n\nGiven the model ( Y_i (_i) ), the log-likelihood function across all observations is:\n\\[\n\\ell(\\beta) = \\sum_{i=1}^n \\left[ -\\exp(X_i^\\top \\beta) + y_i (X_i^\\top \\beta) - \\log(y_i!) \\right]\n\\]\nThis is the function we will maximize to estimate ( ) using maximum likelihood estimation.\ntodo: Update your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g_inv() to be exp() so that \\(\\lambda_i = e^{X_i'\\beta}\\). For example:\npoisson_regression_likelihood &lt;- function(beta, Y, X){\n   ...\n}\n\ndef poisson_log_likelihood_regression(beta, X, y):\n    # Ensure all inputs are NumPy arrays\n    if not isinstance(beta, np.ndarray):\n        beta = np.asarray(beta)\n    if not isinstance(X, np.ndarray):\n        X = np.asarray(X)\n    if not isinstance(y, np.ndarray):\n        y = np.asarray(y)\n\n    eta = X @ beta\n    lambda_ = np.exp(eta)\n\n    return np.sum(-lambda_ + y * eta - gammaln(y + 1))\n\ntodo: Use your function along with R’s optim() or Python’s sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1’s to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\n\nfrom scipy.optimize import minimize\nblueprinty['age_squared'] = blueprinty['age'] ** 2\nblueprinty['age_scaled'] = (blueprinty['age'] - blueprinty['age'].mean()) / blueprinty['age'].std()\nblueprinty['age_squared'] = blueprinty['age_scaled'] ** 2\n\n\n\nblueprinty['intercept'] = 1\nencoded_region = pd.get_dummies(blueprinty['region'], prefix='region', drop_first=True)\nblueprinty = pd.concat([blueprinty, encoded_region], axis=1)\nX = blueprinty[['intercept', 'age_scaled', 'age_squared', 'region_Northeast', 'region_Northwest',\n       'region_South', 'region_Southwest', 'iscustomer']].astype(float).to_numpy()\n\ny = blueprinty['patents'].values\ninitial_beta = np.zeros(X.shape[1])\nresult = minimize(\n    fun=lambda b: -poisson_log_likelihood_regression(b, X, y),\n    x0=initial_beta,\n    method='BFGS'\n)\nbeta_mle = result.x\nlog_lik_at_mle = -result.fun\n\n\n\n\n\n\nVariable\nEstimate (MLE)\n\n\n\n\nintercept\n1.3447\n\n\nage_scaled\n-0.0577\n\n\nage_squared\n-0.1558\n\n\nregion_Northeast\n0.0292\n\n\nregion_Northwest\n-0.0176\n\n\nregion_South\n0.0566\n\n\nregion_Southwest\n0.0506\n\n\niscustomer\n0.2076\n\n\n\n\n\n\n\n   Log-Likelihood at MLE: -3258.07\n\n\n\ntodo: Check your results using R’s glm() function or Python sm.GLM() function.\n\nimport statsmodels.api as sm\n# Use the same standardized/scaled features\nX_sm = blueprinty[['age_scaled', 'age_squared', 'region_Northeast',\n                   'region_Northwest', 'region_South', 'region_Southwest', 'iscustomer']].astype(float).to_numpy()\n\n# Add intercept (statsmodels handles it with sm.add_constant)\nX_sm = sm.add_constant(X_sm)\n\ny_sm = blueprinty['patents']\nmodel = sm.GLM(y_sm, X_sm, family=sm.families.Poisson())\nresult = model.fit()\n\nprint(result.summary())\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                patents   No. Observations:                 1500\nModel:                            GLM   Df Residuals:                     1492\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3258.1\nDate:                Sun, 04 May 2025   Deviance:                       2143.3\nTime:                        16:03:20   Pearson chi2:                 2.07e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.1360\nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          1.3447      0.038     35.059      0.000       1.270       1.420\nx1            -0.0577      0.015     -3.843      0.000      -0.087      -0.028\nx2            -0.1558      0.014    -11.513      0.000      -0.182      -0.129\nx3             0.0292      0.044      0.669      0.504      -0.056       0.115\nx4            -0.0176      0.054     -0.327      0.744      -0.123       0.088\nx5             0.0566      0.053      1.074      0.283      -0.047       0.160\nx6             0.0506      0.047      1.072      0.284      -0.042       0.143\nx7             0.2076      0.031      6.719      0.000       0.147       0.268\n==============================================================================\n\n\ntodo: Interpret the results.\nThe strongest effect is from iscustomer → customers are more innovative Age has a mild downward effect — and gets stronger with age² Region effects are minor — none stand out as very strong\ntodo: What do you conclude about the effect of Blueprinty’s software on patent success? Because the beta coefficients are not directly interpretable, it may help to create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, use X_0 and your fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences."
  },
  {
    "objectID": "projects/hw2/hw2_questions.html#airbnb-case-study",
    "href": "projects/hw2/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\ntodo: Assume the number of reviews is a good proxy for the number of bookings. Perform some exploratory data analysis to get a feel for the data, handle or drop observations with missing values on relevant variables, build one or more models (e.g., a poisson regression model for the number of bookings as proxied by the number of reviews), and interpret model coefficients to describe variation in the number of reviews as a function of the variables provided.\n\nairbnb['price_bins'] = pd.cut(airbnb['price'], bins=[0,500,5000, 10000], right=False)\nairbnb['bathrooms_bins'] = pd.cut(airbnb['bathrooms'], bins=[0, 1, 2, 3, 4, 5, 6], right=False)\nairbnb['bedrooms_bins'] = pd.cut(airbnb['bedrooms'], bins=[0, 1, 2, 3, 4, 5, 6], right=False)\nairbnb['number_of_reviews_bins'] = pd.cut(airbnb['number_of_reviews'], bins=[0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100], right=False)\n\n\n\n\n\n\n\n\n\n\nmean\n\n\n\nnumber_of_reviews\n\n\nbathrooms_bins\n\n\n\n\n\n[0, 1)\n26.604061\n\n\n[1, 2)\n15.846360\n\n\n[2, 3)\n14.943998\n\n\n[3, 4)\n17.843854\n\n\n[4, 5)\n13.571429\n\n\n[5, 6)\n16.923077\n\n\nTotal\n15.837927\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmean\n\n\n\nnumber_of_reviews\n\n\nbathrooms_bins\n\n\n\n\n\n[0, 1)\n26.604061\n\n\n[1, 2)\n15.846360\n\n\n[2, 3)\n14.943998\n\n\n[3, 4)\n17.843854\n\n\n[4, 5)\n13.571429\n\n\n[5, 6)\n16.923077\n\n\nTotal\n15.837927\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:      number_of_reviews   No. Observations:                40395\nModel:                            GLM   Df Residuals:                    40391\nModel Family:                 Poisson   Df Model:                            3\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:            -7.2357e+05\nDate:                Sun, 04 May 2025   Deviance:                   1.3240e+06\nTime:                        16:03:21   Pearson chi2:                 2.16e+06\nNo. Iterations:                     6   Pseudo R-squ. (CS):            0.09222\nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          2.8149      0.004    694.031      0.000       2.807       2.823\nprice         -0.0002    9.7e-06    -25.475      0.000      -0.000      -0.000\nbathrooms     -0.1340      0.004    -35.012      0.000      -0.141      -0.126\nbedrooms       0.1139      0.002     56.587      0.000       0.110       0.118\n==============================================================================\n\n\nWe modeled the number of Airbnb reviews (used as a proxy for bookings) using a Poisson regression with predictors including price, number of bathrooms, and number of bedrooms. The model indicates that higher prices are associated with a small but statistically significant decrease in expected reviews, while listings with more bedrooms tend to receive more reviews, suggesting increased demand for larger spaces. Interestingly, additional bathrooms are associated with fewer reviews, potentially reflecting a trend where more luxurious properties have fewer but longer or higher-priced stays. Overall, the results suggest that price sensitivity and listing size play meaningful roles in driving booking activity.\n\nairbnb = airbnb[airbnb['price'] &lt;= 500]\n\n\nDrop rows with missing values across all relevant columns (before plotting)\n\neda_cols = ['number_of_reviews', 'price', 'bathrooms', 'bedrooms', 'days']\nairbnb_eda = airbnb.dropna(subset=eda_cols)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:      number_of_reviews   No. Observations:                39654\nModel:                            GLM   Df Residuals:                    39650\nModel Family:                 Poisson   Df Model:                            3\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:            -7.1266e+05\nDate:                Sun, 04 May 2025   Deviance:                   1.3039e+06\nTime:                        16:03:21   Pearson chi2:                 2.13e+06\nNo. Iterations:                     6   Pseudo R-squ. (CS):            0.07089\nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          2.7975      0.005    620.600      0.000       2.789       2.806\nprice          0.0002   1.58e-05     10.273      0.000       0.000       0.000\nbathrooms     -0.1415      0.004    -34.929      0.000      -0.149      -0.134\nbedrooms       0.0928      0.002     43.494      0.000       0.089       0.097\n=============================================================================="
  },
  {
    "objectID": "Resume.html",
    "href": "Resume.html",
    "title": "Lowell Resume",
    "section": "",
    "text": "Last updated: 2025-04-05\nDownload PDF file."
  },
  {
    "objectID": "Archive/index.html",
    "href": "Archive/index.html",
    "title": "HW 1",
    "section": "",
    "text": "Question 1\nProf says make a chart\n\n#|echo: false\nprint('Hello World')\n\nHello World\n\nimport matplotlib.pyplot as plt\n\nMatplotlib created a temporary cache directory at /tmp/matplotlib-9dv5v91f because the default path (/home/jovyan/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n\nimport numpy as np\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\nplt.plot(x, y)\nplt.title('Sine Wave')\nplt.xlabel('x')\nplt.ylabel('sin(x)')\nplt.grid()\nplt.savefig('sine_wave.png')\nplt.show()\n\n\n\n\n\n\n\n\n\nimport sys\nprint(\"Python version:\", sys.version)\n\nPython version: 3.12.7 | packaged by conda-forge | (main, Oct  4 2024, 15:56:51) [GCC 13.3.0]\n\n\n\n4+ 7\n\n[1] 11"
  },
  {
    "objectID": "projects/hw2/hw2_notebook.html",
    "href": "projects/hw2/hw2_notebook.html",
    "title": "test",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nMatplotlib created a temporary cache directory at /tmp/matplotlib-c85owgi7 because the default path (/home/jovyan/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n\n\n\nairbnb = pd.read_csv('airbnb.csv')\nblueprinty = pd.read_csv('blueprinty.csv')\n\n\nairbnb.columns\n\nIndex(['Unnamed: 0', 'id', 'days', 'last_scraped', 'host_since', 'room_type',\n       'bathrooms', 'bedrooms', 'price', 'number_of_reviews',\n       'review_scores_cleanliness', 'review_scores_location',\n       'review_scores_value', 'instant_bookable'],\n      dtype='object')\n\n\n\nblueprinty.columns\n\nIndex(['patents', 'region', 'age', 'iscustomer'], dtype='object')\n\n\n\nblueprinty.head()\n\n\n\n\n\n\n\n\npatents\nregion\nage\niscustomer\n\n\n\n\n0\n0\nMidwest\n32.5\n0\n\n\n1\n3\nSouthwest\n37.5\n0\n\n\n2\n4\nNorthwest\n27.0\n1\n\n\n3\n3\nNortheast\n24.5\n0\n\n\n4\n3\nSouthwest\n37.0\n0\n\n\n\n\n\n\n\n\nblueprint_hist = pd.pivot_table(blueprinty, index='iscustomer', values='patents', aggfunc='mean').head()\nblueprint_hist\n\n\n\n\n\n\n\n\npatents\n\n\niscustomer\n\n\n\n\n\n0\n3.473013\n\n\n1\n4.133056\n\n\n\n\n\n\n\n\nblueprint_hist = blueprint_hist.reset_index()\n\n# Create a histogram-style bar chart\nplt.figure(figsize=(6, 4))\nplt.bar(blueprint_hist['iscustomer'].astype(str), blueprint_hist['patents'], edgecolor='black')\n\n# Add labels and title\nplt.xlabel('Is Customer')\nplt.ylabel('Average Number of Patents')\nplt.title('Average Patents by Customer Status')\n\n# Show the plot\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nblueprinty['age'].describe()\n\ncount    1500.000000\nmean       26.357667\nstd         7.242528\nmin         9.000000\n25%        21.000000\n50%        26.000000\n75%        31.625000\nmax        49.000000\nName: age, dtype: float64\n\n\n\nblueprinty['age_bins']= pd.cut(blueprinty['age'], bins=[0, 20, 30, 40, 50], right=False)\nblueprint_hist_age =pd.crosstab(index=blueprinty['age_bins'], columns=blueprinty['iscustomer'],margins=True,margins_name='Total')\ndisplay(blueprint_hist_age)\n\n\nplot_data_age = blueprint_hist_age.drop(index='Total', columns='Total')\n\n# Plot\nplot_data_age.plot(\n    kind='bar',\n    stacked=False,\n    figsize=(8, 5),\n    edgecolor='black',\n    color =( 'skyblue','green',),\n)\n\n# Add labels and title\nplt.xlabel('Age Group')\nplt.ylabel('Count')\nplt.title('Customer Status by Age Group')\nplt.legend(title='Is Customer', labels=['No (0)', 'Yes (1)'])\n\nplt.grid(axis='y', linestyle='--', linewidth=0.7, alpha=0.7)\n\nplt.xticks(rotation=0)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\niscustomer\n0\n1\nTotal\n\n\nage_bins\n\n\n\n\n\n\n\n[0, 20)\n205\n98\n303\n\n\n[20, 30)\n496\n213\n709\n\n\n[30, 40)\n291\n142\n433\n\n\n[40, 50)\n27\n28\n55\n\n\nTotal\n1019\n481\n1500\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nblueprint_hist_region= pd.crosstab(index=blueprinty['region'], columns=blueprinty['iscustomer'],margins=True,margins_name='Total')\nblueprint_hist_region\n\nplot_data_region = blueprint_hist_region.drop(index='Total', columns='Total')\n\n# Plot\nplot_data_region.plot(\n    kind='bar',\n    stacked=False,\n    figsize=(8, 5),\n    edgecolor='black',\n    color=['skyblue','forestgreen']\n)\n\n# Add labels and title\nplt.xlabel('Region')\nplt.ylabel('Count')\nplt.title('Customer Status by Region')\nplt.legend(title='Is Customer', labels=['No (0)', 'Yes (1)'])\n\nplt.grid(axis='y', linestyle='--', linewidth=0.7, alpha=0.7)\n\nplt.xticks(rotation=0)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nfrom math import factorial\n\ndef poisson_distro(lmbda, y):\n    return (np.exp(-lmbda) * (lmbda ** y)) / factorial(y)\n\ndef poisson_likelihood(lmbda, y_array):\n    return np.prod([poisson_distro(lmbda, y_i) for y_i in y_array])\n\nfrom scipy.special import gammaln\n\ndef poisson_log_likelihood(lmbda, y_array):\n    y_array = np.array(y_array)\n    return np.sum(-lmbda + y_array * np.log(lmbda) - gammaln(y_array + 1))\n\n\n\n# Evaluate log-likelihoods across lambda values\nlambda_vals = np.arange(1, 20)\nlog_likelihoods = [poisson_log_likelihood(lmbda, blueprinty['patents'].values) for lmbda in lambda_vals]\n\n# Plot\nplt.figure(figsize=(8, 5))\nplt.plot(lambda_vals, log_likelihoods, marker='o', color='navy')\nplt.title(\"Poisson Log-Likelihood vs. Lambda\")\nplt.xlabel(\"Lambda (λ)\")\nplt.ylabel(\"Log-Likelihood\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nfrom scipy.special import gammaln\n\ndef poisson_log_likelihood_regression(beta, X, y):\n    \"\"\"\n    Log-likelihood function for Poisson regression.\n    \n    Parameters:\n    - beta: array-like, shape (k,)\n    - X: array-like, shape (n, k)  ← includes intercept if desired\n    - y: array-like, shape (n,)\n    \n    Returns:\n    - Scalar: log-likelihood value\n    \"\"\"\n    X = np.array(X)\n    y = np.array(y)\n    beta = np.array(beta)\n    \n    beta = X @ beta                  # linear predictor\n    lambda_ = np.exp(eta)           # inverse link: ensures lambda_i &gt; 0\n    log_lik = np.sum(-lambda_ + y * beta - gammaln(y + 1))\n    \n    return log_lik\n\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.optimize import minimize\nfrom scipy.special import gammaln\n\n# Step 1: Simulate a simple dataset (like blueprinty)\nnp.random.seed(0)\nn = 100\nage = np.random.randint(20, 70, size=n)\nregion = np.random.choice([0, 1], size=n)  # binary region\nis_customer = np.random.choice([0, 1], size=n)\n\n# Design matrix with intercept, age, age^2, region, is_customer\nX = np.column_stack((\n    np.ones(n),           # intercept\n    age,\n    age**2,\n    region,\n    is_customer\n))\n\n# True beta (for simulation purposes)\nbeta_true = np.array([1.0, 0.02, -0.0002, 0.3, 0.5])\n\n# Simulate counts from Poisson model\neta = X @ beta_true\nlambda_ = np.exp(eta)\ny = np.random.poisson(lambda_)\n\n# Step 2: Define the Poisson regression log-likelihood\ndef poisson_log_likelihood_regression(beta, X, y):\n    eta = X @ beta\n    lambda_ = np.exp(eta)\n    return np.sum(-lambda_ + y * eta - gammaln(y + 1))\n\n# Step 3: Maximize the log-likelihood\ninitial_beta = np.zeros(X.shape[1])\n\nresult = minimize(\n    fun=lambda b: -poisson_log_likelihood_regression(b, X, y),\n    x0=initial_beta,\n    method='BFGS'\n)\n\n# Output the estimated coefficients\nbeta_mle = result.x\nlog_lik_at_mle = -result.fun\nprint(\"Estimated Coefficients (MLE):\", beta_mle)\nprint(\"Log-Likelihood at MLE:\", log_lik_at_mle)\n\nEstimated Coefficients (MLE): [0. 0. 0. 0. 0.]\nLog-Likelihood at MLE: -1008.8436872357606\n\n\n/tmp/ipykernel_48080/4112774673.py:33: RuntimeWarning: overflow encountered in exp\n  lambda_ = np.exp(eta)\n/opt/conda/lib/python3.12/site-packages/scipy/optimize/_numdiff.py:590: RuntimeWarning: invalid value encountered in subtract\n  df = fun(x) - f0\n/tmp/ipykernel_48080/4112774673.py:33: RuntimeWarning: overflow encountered in exp\n  lambda_ = np.exp(eta)\n\n\n_todo: Use your function along with R’s optim() or Python’s sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates.\nSpecifically, the first column of X should be all 1’s to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable.\nUse the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors._\n\ndef poisson_log_likelihood_regression(beta, X, y):\n    # Ensure all inputs are NumPy arrays\n    if not isinstance(beta, np.ndarray):\n        beta = np.asarray(beta)\n    if not isinstance(X, np.ndarray):\n        X = np.asarray(X)\n    if not isinstance(y, np.ndarray):\n        y = np.asarray(y)\n\n    eta = X @ beta\n    lambda_ = np.exp(eta)\n\n    return np.sum(-lambda_ + y * eta - gammaln(y + 1))\n\n\nblueprinty['age_squared'] = blueprinty['age'] ** 2\nblueprinty['age_scaled'] = (blueprinty['age'] - blueprinty['age'].mean()) / blueprinty['age'].std()\nblueprinty['age_squared'] = blueprinty['age_scaled'] ** 2\n\n\n\nblueprinty['intercept'] = 1\nencoded_region = pd.get_dummies(blueprinty['region'], prefix='region', drop_first=True)\nblueprinty = pd.concat([blueprinty, encoded_region], axis=1)\nX = blueprinty[['intercept', 'age_scaled', 'age_squared', 'region_Northeast', 'region_Northwest',\n       'region_South', 'region_Southwest', 'iscustomer']].astype(float).to_numpy()\n\ny = blueprinty['patents'].values\ninitial_beta = np.zeros(X.shape[1])\n\n\n\nresult = minimize(\n    fun=lambda b: -poisson_log_likelihood_regression(b, X, y),\n    x0=initial_beta,\n    method='BFGS'\n)\nbeta_mle = result.x\nlog_lik_at_mle = -result.fun\nprint(\"Estimated Coefficients (MLE):\", beta_mle)\nprint(\"Log-Likelihood at MLE:\", log_lik_at_mle)\n\nEstimated Coefficients (MLE): [ 1.34467567 -0.05772321 -0.15581386  0.02917009 -0.0175745   0.05656135\n  0.05057614  0.20759078]\nLog-Likelihood at MLE: -3258.0721454198165\n\n\n\nprint(result.success)\nprint(result.message)\n\nFalse\nDesired error not necessarily achieved due to precision loss.\n\n\n\nimport statsmodels.api as sm\n# Use the same standardized/scaled features\nX_sm = blueprinty[['age_scaled', 'age_squared', 'region_Northeast',\n                   'region_Northwest', 'region_South', 'region_Southwest', 'iscustomer']].astype(float).to_numpy()\n\n# Add intercept (statsmodels handles it with sm.add_constant)\nX_sm = sm.add_constant(X_sm)\n\ny_sm = blueprinty['patents']\nmodel = sm.GLM(y_sm, X_sm, family=sm.families.Poisson())\nresult = model.fit()\n\nprint(result.summary())\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                patents   No. Observations:                 1500\nModel:                            GLM   Df Residuals:                     1492\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3258.1\nDate:                Sun, 04 May 2025   Deviance:                       2143.3\nTime:                        15:51:42   Pearson chi2:                 2.07e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.1360\nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          1.3447      0.038     35.059      0.000       1.270       1.420\nx1            -0.0577      0.015     -3.843      0.000      -0.087      -0.028\nx2            -0.1558      0.014    -11.513      0.000      -0.182      -0.129\nx3             0.0292      0.044      0.669      0.504      -0.056       0.115\nx4            -0.0176      0.054     -0.327      0.744      -0.123       0.088\nx5             0.0566      0.053      1.074      0.283      -0.047       0.160\nx6             0.0506      0.047      1.072      0.284      -0.042       0.143\nx7             0.2076      0.031      6.719      0.000       0.147       0.268\n==============================================================================\n\n\n\nairbnb\n\n\n\n\n\n\n\n\nUnnamed: 0\nid\ndays\nlast_scraped\nhost_since\nroom_type\nbathrooms\nbedrooms\nprice\nnumber_of_reviews\nreview_scores_cleanliness\nreview_scores_location\nreview_scores_value\ninstant_bookable\n\n\n\n\n0\n1\n2515\n3130\n4/2/2017\n9/6/2008\nPrivate room\n1.0\n1.0\n59\n150\n9.0\n9.0\n9.0\nf\n\n\n1\n2\n2595\n3127\n4/2/2017\n9/9/2008\nEntire home/apt\n1.0\n0.0\n230\n20\n9.0\n10.0\n9.0\nf\n\n\n2\n3\n3647\n3050\n4/2/2017\n11/25/2008\nPrivate room\n1.0\n1.0\n150\n0\nNaN\nNaN\nNaN\nf\n\n\n3\n4\n3831\n3038\n4/2/2017\n12/7/2008\nEntire home/apt\n1.0\n1.0\n89\n116\n9.0\n9.0\n9.0\nf\n\n\n4\n5\n4611\n3012\n4/2/2017\n1/2/2009\nPrivate room\nNaN\n1.0\n39\n93\n9.0\n8.0\n9.0\nt\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n40623\n40624\n18008937\n266\n4/2/2017\n7/10/2016\nEntire home/apt\n1.5\n2.0\n150\n0\nNaN\nNaN\nNaN\nt\n\n\n40624\n40625\n18009045\n366\n4/2/2017\n4/1/2016\nPrivate room\n1.0\n1.0\n125\n0\nNaN\nNaN\nNaN\nf\n\n\n40625\n40626\n18009065\n587\n4/2/2017\n8/24/2015\nPrivate room\n1.0\n1.0\n80\n0\nNaN\nNaN\nNaN\nt\n\n\n40626\n40627\n18009650\n335\n4/2/2017\n5/2/2016\nPrivate room\n1.0\n1.0\n69\n0\nNaN\nNaN\nNaN\nt\n\n\n40627\n40628\n18009669\n1\n4/2/2017\n4/1/2017\nEntire home/apt\n1.0\n1.0\n115\n0\nNaN\nNaN\nNaN\nt\n\n\n\n\n40628 rows × 14 columns\n\n\n\n\ncols_of_interets = ['days','bathrooms','bedrooms','number_of_reviews','review_scores_location','review_scores_value','review_scores_cleanliness',]\nfor i in cols_of_interets:\n    airbnb[i].describe()\n    plt.scatter(airbnb['price'], airbnb[i])\n    plt.xlabel('Price')\n    plt.ylabel(i)\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nairbnb['price_bins'] = pd.cut(airbnb['price'], bins=[0,500,5000, 10000], right=False)\nairbnb['bathrooms_bins'] = pd.cut(airbnb['bathrooms'], bins=[0, 1, 2, 3, 4, 5, 6], right=False)\nairbnb['bedrooms_bins'] = pd.cut(airbnb['bedrooms'], bins=[0, 1, 2, 3, 4, 5, 6], right=False)\nairbnb['number_of_reviews_bins'] = pd.cut(airbnb['number_of_reviews'], bins=[0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100], right=False)\n\n\nbathroom_hist = pd.pivot_table(airbnb, index='bathrooms_bins', values='number_of_reviews', aggfunc=['mean'],margins=True,margins_name='Total')\ndisplay(bathroom_hist)\nplot_data_bathrooms = bathroom_hist.drop(index='Total')\n\n# Plot\nplot_data_bathrooms.plot(\n    kind='bar',\n    stacked=False,\n    figsize=(8, 5),\n    edgecolor='black',\n    color =('green',),\n)\n\n# Add labels and title\nplt.xlabel('NR of Bathrooms')\nplt.ylabel('Average Number of Reviews')\nplt.title('Average Number of Reviews by Bathrooms')\nplt.legend().set_visible(False)\nplt.grid(axis='y', linestyle='--', linewidth=0.7, alpha=0.7)\n\nplt.xticks(rotation=0)\nplt.tight_layout()\nplt.show()\n\n/tmp/ipykernel_48080/364120488.py:1: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n  bathroom_hist = pd.pivot_table(airbnb, index='bathrooms_bins', values='number_of_reviews', aggfunc=['mean'],margins=True,margins_name='Total')\n\n\n\n\n\n\n\n\n\nmean\n\n\n\nnumber_of_reviews\n\n\nbathrooms_bins\n\n\n\n\n\n[0, 1)\n26.604061\n\n\n[1, 2)\n15.846360\n\n\n[2, 3)\n14.943998\n\n\n[3, 4)\n17.843854\n\n\n[4, 5)\n13.571429\n\n\n[5, 6)\n16.923077\n\n\nTotal\n15.837927\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprice_hist = pd.pivot_table(airbnb, index='price_bins', values='number_of_reviews', aggfunc=['mean'],margins=True,margins_name='Total')\ndisplay(bathroom_hist)\nplot_data_price = price_hist.drop(index='Total')\n\n# Plot\nplot_data_price.plot(\n    kind='bar',\n    stacked=False,\n    figsize=(8, 5),\n    edgecolor='black',\n    color =('green',),\n)\n\n# Add labels and title\nplt.xlabel('price_bins')\nplt.ylabel('Average Number of Reviews')\nplt.title('Average Number of Reviews by Price')\nplt.legend().set_visible(False)\nplt.grid(axis='y', linestyle='--', linewidth=0.7, alpha=0.7)\n\nplt.xticks(rotation=0)\nplt.tight_layout()\nplt.show()\n\n/tmp/ipykernel_48080/3684250169.py:1: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n  price_hist = pd.pivot_table(airbnb, index='price_bins', values='number_of_reviews', aggfunc=['mean'],margins=True,margins_name='Total')\n\n\n\n\n\n\n\n\n\nmean\n\n\n\nnumber_of_reviews\n\n\nbathrooms_bins\n\n\n\n\n\n[0, 1)\n26.604061\n\n\n[1, 2)\n15.846360\n\n\n[2, 3)\n14.943998\n\n\n[3, 4)\n17.843854\n\n\n[4, 5)\n13.571429\n\n\n[5, 6)\n16.923077\n\n\nTotal\n15.837927\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport seaborn as sns\nfrom statsmodels.api import GLM\nfrom statsmodels.genmod.families import Poisson\n\n# Step 1: Exploratory Data Analysis (EDA)\n\n# Distribution of the number of reviews\nsns.histplot(airbnb['number_of_reviews'], bins=30, kde=True)\nplt.title('Distribution of Number of Reviews')\nplt.xlabel('Number of Reviews')\nplt.ylabel('Frequency')\nplt.show()\n\n# Correlation heatmap for numerical variables\nnumerical_cols = ['days', 'bathrooms', 'bedrooms', 'price', 'number_of_reviews']\nsns.heatmap(airbnb[numerical_cols].corr(), annot=True, cmap='coolwarm')\nplt.title('Correlation Heatmap')\nplt.show()\n\n# Scatter plot of price vs. number of reviews\nsns.scatterplot(x='price', y='number_of_reviews', data=airbnb)\nplt.title('Price vs. Number of Reviews')\nplt.xlabel('Price')\nplt.ylabel('Number of Reviews')\nplt.show()\n\n# Step 2: Handle Missing Values\n# Drop rows with missing values in relevant columns\nrelevant_cols = ['number_of_reviews', 'price', 'bathrooms', 'bedrooms']\nairbnb_cleaned = airbnb.dropna(subset=relevant_cols)\n\n# Step 3: Build a Poisson Regression Model\n\n# Define dependent and independent variables\nX = airbnb_cleaned[['price', 'bathrooms', 'bedrooms']]\nX = sm.add_constant(X)  # Add intercept\ny = airbnb_cleaned['number_of_reviews']\n\n# Fit the Poisson regression model\npoisson_model = GLM(y, X, family=Poisson()).fit()\n\n# Step 4: Interpret Model Coefficients\nprint(poisson_model.summary())\n\n# Interpretation:\n# The coefficients represent the log change in the expected number of reviews for a one-unit increase in the predictor.\n# For example, if the coefficient for `price` is -0.01, it means a one-unit increase in price decreases the expected number of reviews by approximately 1% (exp(-0.01) ≈ 0.99).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:      number_of_reviews   No. Observations:                40395\nModel:                            GLM   Df Residuals:                    40391\nModel Family:                 Poisson   Df Model:                            3\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:            -7.2357e+05\nDate:                Sun, 04 May 2025   Deviance:                   1.3240e+06\nTime:                        15:54:33   Pearson chi2:                 2.16e+06\nNo. Iterations:                     6   Pseudo R-squ. (CS):            0.09222\nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          2.8149      0.004    694.031      0.000       2.807       2.823\nprice         -0.0002    9.7e-06    -25.475      0.000      -0.000      -0.000\nbathrooms     -0.1340      0.004    -35.012      0.000      -0.141      -0.126\nbedrooms       0.1139      0.002     56.587      0.000       0.110       0.118\n==============================================================================\n\n\n\nairbnb = airbnb[airbnb['price'] &lt;= 2000]"
  },
  {
    "objectID": "personnel.html",
    "href": "personnel.html",
    "title": "Personnel Projects",
    "section": "",
    "text": "This is a test"
  }
]